{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063ead3a-3833-45f5-a4ea-0724f4b39ce6",
   "metadata": {},
   "source": [
    "# mcdc_analysis_d22a\n",
    "\n",
    "## Purpose\n",
    "Using Monte Carlo Drift Correction (MCDC), analyse data produced by [data_d22a.ipynb](https://github.com/grandey/d22a-mcdc/blob/main/data_d22a.ipynb), including production of figures and tables.\n",
    "\n",
    "## Input data requirements\n",
    "NetCDF files in [data/](https://github.com/grandey/d22a-mcdc/tree/main/data/) (produced by [data_d22a.ipynb](https://github.com/grandey/d22a-mcdc/blob/main/data_d22a.ipynb)), each containing a global mean time series for a given variable, AOGCM variant, and CMIP6 experiment.\n",
    "\n",
    "## Output files written\n",
    "Figures (TODO) and tables (TODO).\n",
    "\n",
    "## History\n",
    "BSG, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40cb6cf-7c6d-474f-88ad-8b18ced4fa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 17 14:43:01 +08 2022\n"
     ]
    }
   ],
   "source": [
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00885783-072d-446e-9c16-7c7142a5af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c4b89e-c4a2-4828-bc12-94114c9e9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b71f3c-c030-499a-a137-598a697574ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarray: 2022.6.0\n",
      "numpy: 1.23.1\n",
      "pandas: 1.4.3\n",
      "statsmodels.api: 0.13.2\n",
      "xarray: 2022.6.0\n"
     ]
    }
   ],
   "source": [
    "# Package versions\n",
    "for p in [xr, np, pd, sm, xr]:\n",
    "    print(f'{p.__name__}: {p.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd637c4d-5cca-42f4-a700-187e38031645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(PCG64) at 0x170393220"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random number generator\n",
    "rng = np.random.default_rng(12345)\n",
    "rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d945729-4214-4d51-8aad-5280c0c59166",
   "metadata": {},
   "source": [
    "## Identify AOGCM variants (source-member pairs)\n",
    "Note: the AOGCM variants identified should match those identified by data_d22a.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3900e577-986a-4678-aea8-1ca48835df95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 source-member pairs identified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ACCESS-CM2_r1i1p1f1',\n",
       " 'ACCESS-ESM1-5_r1i1p1f1',\n",
       " 'CMCC-CM2-SR5_r1i1p1f1',\n",
       " 'CMCC-ESM2_r1i1p1f1',\n",
       " 'CNRM-CM6-1_r1i1p1f2',\n",
       " 'CNRM-ESM2-1_r1i1p1f2',\n",
       " 'CanESM5_r1i1p1f1',\n",
       " 'EC-Earth3-Veg-LR_r1i1p1f1',\n",
       " 'EC-Earth3-Veg_r1i1p1f1',\n",
       " 'EC-Earth3_r1i1p1f1',\n",
       " 'GISS-E2-1-G_r1i1p5f1',\n",
       " 'GISS-E2-1-H_r1i1p1f2',\n",
       " 'IPSL-CM6A-LR_r1i1p1f1',\n",
       " 'MIROC6_r1i1p1f1',\n",
       " 'MPI-ESM1-2-HR_r1i1p1f1',\n",
       " 'MPI-ESM1-2-LR_r1i1p1f1',\n",
       " 'MRI-ESM2-0_r1i1p1f1',\n",
       " 'NorESM2-LM_r1i1p1f1',\n",
       " 'NorESM2-MM_r1i1p1f1',\n",
       " 'UKESM1-0-LL_r1i1p1f2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location of data produced by data_d22a.ipynb\n",
    "in_base = pathlib.Path.cwd() / 'data' / 'regrid_missto0_yearmean_fldmean_mergetime'\n",
    "\n",
    "# Core variables required\n",
    "core_var_list = ['rsdt', 'rsut', 'rlut', # R = rsdt-rsut-rlut\n",
    "                 'hfds',  # H (without flux correction)\n",
    "                 'zostoga']  # Z\n",
    "\n",
    "# Experiments required (with corresponding names, used for figs later)\n",
    "exp_dict = {'piControl': 'Control', 'historical': 'Historical',\n",
    "            'ssp126': 'SSP1-2.6', 'ssp245': 'SSP2-4.5',\n",
    "            'ssp370': 'SSP3-7.0', 'ssp585': 'SSP5-8.5'}\n",
    "\n",
    "# Identify source-member pairs to use\n",
    "source_member_list = sorted([d.name for d in in_base.glob(f'rsdt/[!.]*_*')])  # this list will be reduced\n",
    "for source_member in source_member_list.copy():  # loop over copy of source-member pairs to check data availability\n",
    "    for var in core_var_list:  # loop over required variables\n",
    "        for exp in exp_dict.keys():  # loop over experiments\n",
    "            #in_fns = sorted(in_base.glob(f'{var}/{source_member}/{var}_{source_member}_{exp}.mergetime.nc'))\n",
    "            in_fn = in_base.joinpath(f'{var}/{source_member}/{var}_{source_member}_{exp}.mergetime.nc')\n",
    "            if not in_fn.is_file():  # if input file for this experiment does not exist...\n",
    "                try:\n",
    "                    source_member_list.remove(source_member)  # ... do not use this source-member pair\n",
    "                except ValueError:  # when source-member pair has previously been removed\n",
    "                    pass\n",
    "\n",
    "print(f'{len(source_member_list)} source-member pairs identified.')\n",
    "source_member_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f8c6e-a0a4-4d7f-8394-acb36dab6ef0",
   "metadata": {},
   "source": [
    "## Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f79f6e-1267-44d2-bd0f-642e49dcf654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_da_dict contains 606 DataArrays\n",
      "CPU times: user 1.5 s, sys: 46.2 ms, total: 1.54 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Dictionary to hold input DataArrays\n",
    "in_da_dict = {}  # keys will be tuples of (source_member, exp, var)\n",
    "\n",
    "# List of input data variables \n",
    "in_var_list = ['rsdt', 'rsut', 'rlut',  # R = rsdt-rsut-rlut\n",
    "               'hfds',  # H (without flux correction)\n",
    "               'hfcorr',  # flux correction, available for very few source-member pairs\n",
    "               'zostoga']  # Z\n",
    "\n",
    "# Loop over source-member pairs, experiments, and variables\n",
    "for source_member in source_member_list:\n",
    "    for exp in exp_dict.keys():\n",
    "        for var in in_var_list:\n",
    "            # Read input data (if they exist)\n",
    "            in_fn = in_base.joinpath(f'{var}/{source_member}/{var}_{source_member}_{exp}.mergetime.nc')\n",
    "            try:\n",
    "                in_ds = xr.open_dataset(in_fn)  # Dataset\n",
    "                in_da = in_ds[var]  # DataArray\n",
    "                # Remove degenerate lon and lat dimensions\n",
    "                in_da = in_da.squeeze()\n",
    "                # Convert time units to year\n",
    "                in_da['time'] = (in_da['time'] // 1e4).astype(int)\n",
    "                in_da['time'].attrs['units'] = 'a'\n",
    "                # Convert zostoga units to mm\n",
    "                if var == 'zostoga':\n",
    "                    in_da.data = in_da.data * 1e3\n",
    "                    in_da.attrs['units'] = 'mm'\n",
    "                # Check: do data have non-zero values?\n",
    "                if (in_da**2).sum() == 0:\n",
    "                    print(f'Skipping {source_member} {exp} {var} (no non-zero values)')\n",
    "                else:\n",
    "                    # Save to dictionary\n",
    "                    in_da_dict[(source_member, exp, var)] = in_da\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "print(f'in_da_dict contains {len(in_da_dict)} DataArrays')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532fe257-f41e-41f7-b723-61620689d93a",
   "metadata": {},
   "source": [
    "## Basic processing of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57847362-7975-405b-bdda-56de96a9b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR_r1i1p1f1 piControl hfds had missing years; using period before gap; length 1800 -> 1000.\n"
     ]
    }
   ],
   "source": [
    "# Are there any gaps (missing years) in the data coverage?\n",
    "for source_member in source_member_list:\n",
    "    for exp in exp_dict.keys():\n",
    "        for var in in_var_list:\n",
    "            try:\n",
    "                in_da = in_da_dict[(source_member, exp, var)]\n",
    "                # Is the interval betweeen successive time coords always 1 year?\n",
    "                intervals = in_da.time.data[1:] - in_da.time.data[:-1]\n",
    "                if not np.all(intervals == 1):\n",
    "                    # If a gap is found, limit to period before gap\n",
    "                    gap_i = int(np.where(intervals != 1)[0])  # identify first gap\n",
    "                    gap_yr = in_da.time.data[gap_i]  # final year before gap\n",
    "                    len_old = len(in_da)  # old length\n",
    "                    in_da = in_da.where(in_da.time <= gap_yr, drop=True)  # limit data\n",
    "                    in_da_dict[(source_member, exp, var)] = in_da  # update dict\n",
    "                    len_new = len(in_da)  # new length\n",
    "                    print(f'{source_member} {exp} {var} had missing years; using period before gap; '\n",
    "                          f'length {len_old} -> {len_new}.')\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ba0ab8-5c8d-42cd-af56-da26b0ea4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5_r1i1p1f1 ssp585 has inconsistent time coord\n",
      "  End years differ: [2300, 2300, 2300, 2300, 2180]\n",
      "  Limiting to shared period of 1850-2180 (331 years)\n",
      "EC-Earth3-Veg_r1i1p1f1 piControl has inconsistent time coord\n",
      "  End years differ: [3849, 3849, 3849, 2349, 2349]\n",
      "  Limiting to shared period of 1850-2349 (500 years)\n",
      "IPSL-CM6A-LR_r1i1p1f1 piControl has inconsistent time coord\n",
      "  End years differ: [3849, 3849, 3849, 2849, 3849]\n",
      "  Limiting to shared period of 1850-2849 (1000 years)\n",
      "MIROC6_r1i1p1f1 piControl has inconsistent time coord\n",
      "  End years differ: [3999, 3999, 3999, 3699, 3999]\n",
      "  Limiting to shared period of 3200-3699 (500 years)\n",
      "UKESM1-0-LL_r1i1p1f2 piControl has inconsistent time coord\n",
      "  End years differ: [3839, 3839, 3839, 3839, 3059]\n",
      "  Limiting to shared period of 1960-3059 (1100 years)\n"
     ]
    }
   ],
   "source": [
    "# For a given source-member and experiment, is the time coverage consistent between core variables?\n",
    "for source_member in source_member_list:\n",
    "    for exp in exp_dict.keys():\n",
    "        try:\n",
    "            # Time coords for primary variables of interest\n",
    "            time1 = in_da_dict[(source_member, exp, 'rsdt')].time.data\n",
    "            time2 = in_da_dict[(source_member, exp, 'rsut')].time.data\n",
    "            time3 = in_da_dict[(source_member, exp, 'rlut')].time.data\n",
    "            time4 = in_da_dict[(source_member, exp, 'hfds')].time.data\n",
    "            time5 = in_da_dict[(source_member, exp, 'zostoga')].time.data\n",
    "            # Are the time coords the same?\n",
    "            if not (np.array_equal(time1, time2) and np.array_equal(time1, time3) and\n",
    "                    np.array_equal(time1, time4) and np.array_equal(time1, time5)):\n",
    "                print(f'{source_member} {exp} has inconsistent time coord')\n",
    "                # Are the start years the same?\n",
    "                start_list = [t[0] for t in [time1, time2, time3, time4, time5]]\n",
    "                if len(set(start_list)) > 1:\n",
    "                    print(f'  Start years differ: {start_list}')\n",
    "                start_max = max(start_list)  # earliest year available for all\n",
    "                # Are the end years the same?\n",
    "                end_list = [t[-1] for t in [time1, time2, time3, time4, time5]]\n",
    "                if len(set(end_list)) > 1:\n",
    "                    print(f'  End years differ: {end_list}')\n",
    "                end_min = min(end_list)  # latest year availabe for all\n",
    "                # Limit to shared period\n",
    "                print(f'  Limiting to shared period of {start_max}-{end_min} ({end_min-start_max+1} years)')\n",
    "                for var in in_var_list:  # limit time coord for all variables (including hfcorr)\n",
    "                    try:\n",
    "                        in_da = in_da_dict[(source_member, exp, var)]\n",
    "                        in_da = in_da.where((in_da.time >= start_max) & (in_da.time <= end_min), drop=True)\n",
    "                        in_da_dict[(source_member, exp, var)] = in_da\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba54b84-d1ce-490c-9430-834be49b00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift PI control start year to 1 (arbitrary)\n",
    "for source_member in source_member_list:\n",
    "    for var in in_var_list:\n",
    "        try:\n",
    "            in_da = in_da_dict[(source_member, 'piControl', var)]\n",
    "            in_da['time'] = in_da['time'] - in_da['time'][0] + 1  # shift\n",
    "        except IndexError:\n",
    "            print('IndexError encountered:', source_member, var, in_da)\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7de0ef-037f-46a5-93f0-ebaa728d2b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2_r1i1p1f1 piControl has 500 years\n",
      "ACCESS-ESM1-5_r1i1p1f1 piControl has 1000 years\n",
      "CMCC-CM2-SR5_r1i1p1f1 piControl has 500 years\n",
      "CMCC-ESM2_r1i1p1f1 piControl has 500 years\n",
      "CNRM-CM6-1_r1i1p1f2 piControl has 500 years\n",
      "CNRM-ESM2-1_r1i1p1f2 piControl has 500 years\n",
      "CanESM5_r1i1p1f1 piControl has 1000 years\n",
      "EC-Earth3-Veg-LR_r1i1p1f1 piControl has 501 years\n",
      "EC-Earth3-Veg_r1i1p1f1 piControl has 500 years\n",
      "EC-Earth3_r1i1p1f1 piControl has 501 years\n",
      "GISS-E2-1-G_r1i1p5f1 piControl has 201 years\n",
      "GISS-E2-1-H_r1i1p1f2 piControl has 451 years\n",
      "IPSL-CM6A-LR_r1i1p1f1 piControl has 1000 years\n",
      "MIROC6_r1i1p1f1 piControl has 500 years\n",
      "MPI-ESM1-2-HR_r1i1p1f1 piControl has 500 years\n",
      "MPI-ESM1-2-LR_r1i1p1f1 piControl has 1000 years\n",
      "MRI-ESM2-0_r1i1p1f1 piControl has 701 years\n",
      "NorESM2-LM_r1i1p1f1 piControl has 501 years\n",
      "NorESM2-MM_r1i1p1f1 piControl has 500 years\n",
      "UKESM1-0-LL_r1i1p1f2 piControl has 1100 years\n"
     ]
    }
   ],
   "source": [
    "# How much PI control data are available for each source-member pair?\n",
    "for source_member in source_member_list:\n",
    "    in_da = in_da_dict[(source_member, 'piControl', 'zostoga')]\n",
    "    print(f'{source_member} piControl has {len(in_da)} years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f8ff69-77d7-472f-b04c-cb8983815651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit SSPs to 2100 for consistency\n",
    "for source_member in source_member_list:\n",
    "    for exp in exp_dict.keys():\n",
    "        if 'ssp' in exp:\n",
    "            for var in in_var_list:\n",
    "                try:\n",
    "                    time_data = in_da_dict[(source_member, exp, var)].time.data\n",
    "                    if time_data[-1] > 2100: \n",
    "                        in_da = in_da_dict[(source_member, exp, var)]\n",
    "                        in_da = in_da.where(in_da.time <= 2100, drop=True)\n",
    "                        in_da_dict[(source_member, exp, var)] = in_da\n",
    "                except KeyError:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfee93dd-d427-4566-a61b-639c87ac704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0_r1i1p1f1 ssp126 zostoga year-2015 shifted from 2.0144 to 69.3741\n",
      "MRI-ESM2-0_r1i1p1f1 ssp245 zostoga year-2015 shifted from 2.1230 to 69.3741\n",
      "MRI-ESM2-0_r1i1p1f1 ssp370 zostoga year-2015 shifted from 2.3462 to 69.3741\n",
      "MRI-ESM2-0_r1i1p1f1 ssp585 zostoga year-2015 shifted from 1.2473 to 69.3741\n"
     ]
    }
   ],
   "source": [
    "# Correct discontinuities in MRI-ESM2-0_r1i1p1f1 zostoga SSP time series\n",
    "for source_member in ['MRI-ESM2-0_r1i1p1f1',]:\n",
    "    # Using historical time series, extrapolate to 2015 based on 2014-2013 diff\n",
    "    in_da = in_da_dict[(source_member, 'historical', 'zostoga')]\n",
    "    diff = in_da[-1].data - in_da[-2].data\n",
    "    extrap_2015 = in_da[-1].data + diff\n",
    "    # Shift SSP data from 2015 onwards to match extrapolation bridging discontinuity\n",
    "    for exp in exp_dict.keys():\n",
    "        if 'ssp' in exp:\n",
    "            in_da = in_da_dict[(source_member, exp, 'zostoga')]\n",
    "            old_2015 = in_da.sel(time=2015).data  # current value for 2015\n",
    "            correction = extrap_2015 - old_2015  # correction to apply\n",
    "            new_da = xr.concat([in_da.sel(time=slice(1850,2014)),\n",
    "                                (in_da.sel(time=slice(2015,2100))+correction)], dim='time')  # apply correction\n",
    "            new_2015 = new_da.sel(time=2015).data  # new value for 2015\n",
    "            in_da_dict[(source_member, exp, 'zostoga')] = new_da\n",
    "            print(f'{source_member} {exp} zostoga year-2015 shifted from {old_2015:.4f} to {new_2015:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb258b-38c4-4349-b9eb-e3d6d8d2a448",
   "metadata": {},
   "source": [
    "## Calculate uncorrected $R$, ${\\int}R$, $H$, ${\\int}H$, and $\\Delta Z$ from input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e786178-06f2-44e4-8e11-57178fcab56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0_r1i1p1f1 piControl has hfcorr (mean=0.288, std=0.010)\n",
      "MRI-ESM2-0_r1i1p1f1 historical has hfcorr (mean=0.283, std=0.013)\n",
      "MRI-ESM2-0_r1i1p1f1 ssp126 has hfcorr (mean=0.263, std=0.030)\n",
      "MRI-ESM2-0_r1i1p1f1 ssp245 has hfcorr (mean=0.259, std=0.038)\n",
      "MRI-ESM2-0_r1i1p1f1 ssp370 has hfcorr (mean=0.255, std=0.045)\n",
      "MRI-ESM2-0_r1i1p1f1 ssp585 has hfcorr (mean=0.251, std=0.052)\n",
      "da_dict contains 600 DataArrays\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold DataArrays\n",
    "da_dict = {}  # keys will be tuples of (source_member, exp, var)\n",
    "\n",
    "# Loop over source-member pairs and experiments\n",
    "for source_member in source_member_list:\n",
    "    for exp in exp_dict.keys():\n",
    "        # R = rsdt-rsut-rlut\n",
    "        r_da = (in_da_dict[(source_member, exp, 'rsdt')]\n",
    "                - in_da_dict[(source_member, exp, 'rsut')]\n",
    "                - in_da_dict[(source_member, exp, 'rlut')])\n",
    "        da_dict[(source_member, exp, 'R')] = r_da  # R\n",
    "        da_dict[(source_member, exp, 'R')].attrs['units'] = 'W m$^{-2}$'\n",
    "        # \\int R\n",
    "        da_dict[(source_member, exp, '\\int R')] = r_da.cumsum()\n",
    "        da_dict[(source_member, exp, '\\int R')].attrs['units'] = 'W m$^{-2}$ a'  # a is year\n",
    "        # H = hfds+hfcorr (ie apply flux correction if it is non-zero)\n",
    "        try:\n",
    "            # If hfcorr exists, add it to hfds\n",
    "            in_da = in_da_dict[(source_member, exp, 'hfcorr')].copy()\n",
    "            print(f'{source_member} {exp} has hfcorr (mean={in_da.mean().data:0.3f}, std={in_da.std().data:0.3f})')\n",
    "            da_dict[(source_member, exp, 'H')] = in_da_dict[(source_member, exp, 'hfds')] + in_da\n",
    "        except KeyError:\n",
    "            # If hfcorr does not exist, assume it is zero and just use hfds\n",
    "            da_dict[(source_member, exp, 'H')] = in_da_dict[(source_member, exp, 'hfds')].copy()\n",
    "        da_dict[(source_member, exp, 'H')].attrs['units'] = 'W m$^{-2}$'\n",
    "        # \\int H\n",
    "        da_dict[(source_member, exp, '\\int H')] = da_dict[(source_member, exp, 'H')].cumsum()\n",
    "        da_dict[(source_member, exp, '\\int H')].attrs['units'] = 'W m$^{-2}$ a'\n",
    "        # \\Delta Z = zostoga (using first year as reference for zero)\n",
    "        z_da = in_da_dict[(source_member, exp, 'zostoga')].copy()\n",
    "        z_da -= z_da[0]\n",
    "        da_dict[(source_member, exp, '\\Delta Z')] = z_da\n",
    "\n",
    "print(f'da_dict contains {len(da_dict)} DataArrays')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa8827-52f0-42c7-919e-07803b2ed245",
   "metadata": {},
   "source": [
    "## Constants and conversion factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93f34d16-00ae-44e3-a528-75c0948e325c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                source_member    area_earth\n",
      "0         ACCESS-CM2_r1i1p1f1  5.100645e+14\n",
      "1      ACCESS-ESM1-5_r1i1p1f1  5.100645e+14\n",
      "2       CMCC-CM2-SR5_r1i1p1f1  5.100645e+14\n",
      "3          CMCC-ESM2_r1i1p1f1  5.100645e+14\n",
      "4         CNRM-CM6-1_r1i1p1f2  5.100645e+14\n",
      "5        CNRM-ESM2-1_r1i1p1f2  5.100645e+14\n",
      "6            CanESM5_r1i1p1f1  5.100645e+14\n",
      "7   EC-Earth3-Veg-LR_r1i1p1f1  5.100645e+14\n",
      "8      EC-Earth3-Veg_r1i1p1f1  5.100645e+14\n",
      "9          EC-Earth3_r1i1p1f1  5.100645e+14\n",
      "10       GISS-E2-1-G_r1i1p5f1  5.100645e+14\n",
      "11       GISS-E2-1-H_r1i1p1f2  5.100645e+14\n",
      "12      IPSL-CM6A-LR_r1i1p1f1  5.100645e+14\n",
      "13            MIROC6_r1i1p1f1  5.100645e+14\n",
      "14     MPI-ESM1-2-HR_r1i1p1f1  5.100645e+14\n",
      "15     MPI-ESM1-2-LR_r1i1p1f1  5.100645e+14\n",
      "16        MRI-ESM2-0_r1i1p1f1  5.100645e+14\n",
      "17        NorESM2-LM_r1i1p1f1  5.100645e+14\n",
      "18        NorESM2-MM_r1i1p1f1  5.100645e+14\n",
      "19       UKESM1-0-LL_r1i1p1f2  5.100645e+14\n",
      "area_earth = 5.101e+14 m2\n"
     ]
    }
   ],
   "source": [
    "# Total area of earth\n",
    "in_fn = pathlib.Path.cwd() / 'data' / 'area_earth.csv'  # produced by data_d22a.ipynb\n",
    "area_df = pd.read_csv(in_fn)  # read to DataFrame\n",
    "print(area_df)  # print\n",
    "area_earth = area_df['area_earth'].mean()  # convert to single number\n",
    "print(f'area_earth = {area_earth:.3e} m2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f979924-7c51-40dd-a7fc-0bce03b46e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 W m-2 a = 0.0161 YJ\n",
      "1 YJ = 62.17 W m-2 a\n"
     ]
    }
   ],
   "source": [
    "# Conversion factor for W m-2 a -> YJ\n",
    "convert_Wm2a_YJ = area_earth * 365 * 24 * 60 * 60 / 1e24\n",
    "print(f'1 W m-2 a = {convert_Wm2a_YJ:.4f} YJ')\n",
    "print(f'1 YJ = {1/convert_Wm2a_YJ:.2f} W m-2 a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8123552-3057-41fb-bcc8-e9b7856b7dae",
   "metadata": {},
   "source": [
    "## Monte Carlo Drift Correction functions\n",
    "\n",
    "**`calc_trend()`** and **`calc_mean()`** calculate the trend/mean of a time series (an xr.DataArray).\n",
    "By default, the trend/mean is perturbed by a random error, drawn from a Gaussian distribution corresponding to the standard errror.\n",
    "\n",
    "**`sample_segments_calc_trends_means()`** randomly draws segments of a specified length from a list of DataArrays.\n",
    "The DataArrays are sampled consistently using the same 150 year segments.\n",
    "For each segment, the function uses `calc_trend()` and `calc_mean()` to calculate trends and means (with random errors included by default).\n",
    "`sample_segments_calc_trends_means()` returns trends (list of arrays), means (list of arrays), and the start years of the segments sampled (array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b45f87-f050-4c1e-9c2a-34dcdf6ead54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 ms, sys: 534 µs, total: 1.59 ms\n",
      "Wall time: 1.07 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.053359242656797146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_trend(data_da, inc_rand_error=True):\n",
    "    \"\"\"Calculate the trend of a time series (xr.DataArray), include random error (optional), and return trend.\"\"\"\n",
    "    # Linear regression (using statsmodels)\n",
    "    x_in = sm.add_constant(data_da.time, prepend=True)\n",
    "    sm_reg = sm.OLS(data_da.data, x_in).fit()\n",
    "    b = sm_reg.params[1]  # slope\n",
    "    # Include random error using the standard error (assuming Gaussian)?\n",
    "    if inc_rand_error:\n",
    "        bse = sm_reg.bse[1]  # standard error on slope\n",
    "        trend = rng.normal(loc=b, scale=bse)  # sample from Gaussian\n",
    "    else:\n",
    "        trend = b\n",
    "    return trend\n",
    "\n",
    "# Example\n",
    "data_da = da_dict[(source_member_list[-1], 'piControl', '\\Delta Z')].copy()\n",
    "%time calc_trend(data_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd9aadb-b723-4d7c-b2d0-8ff8cafc79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 373 µs, sys: 266 µs, total: 639 µs\n",
      "Wall time: 379 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-40.920236559730064"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_mean(data_da, inc_rand_error=True):\n",
    "    \"\"\"Calculate the mean of a time series (xr.DataArray), include random error (optional), and return result.\"\"\"\n",
    "    # Mean\n",
    "    m = np.mean(data_da.data)\n",
    "    # Include random error using the standard error (assuming Gaussian)?\n",
    "    if inc_rand_error:\n",
    "        sem = stats.sem(data_da.data)  # standard eror of mean\n",
    "        res = rng.normal(loc=m, scale=sem)  # sample from Gaussian\n",
    "    else:\n",
    "        res = m\n",
    "    return res\n",
    "\n",
    "# Example\n",
    "data_da = da_dict[(source_member_list[-1], 'piControl', '\\Delta Z')].copy()\n",
    "%time calc_mean(data_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "733d15a2-00b3-4016-a6ed-df9f3e8fb951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible start years: 1 - 951\n",
      "Randomly chosen start years: [195 759 612]\n",
      "Trends: [-0.00010098 -0.0003937   0.00044171]\n",
      "Means: [-0.01634032  0.04432896  0.00087912]\n",
      "Trends: [1.02814916e-03 1.94414061e-05 2.44629685e-05]\n",
      "Means: [-0.27763762 -0.24957567 -0.25250733]\n",
      "Trends: [-0.06995799 -0.01925332 -0.00144673]\n",
      "Means: [-29.38422147 -54.77843728 -49.6483107 ]\n",
      "CPU times: user 7.89 ms, sys: 1.5 ms, total: 9.39 ms\n",
      "Wall time: 8.11 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([-0.00010098, -0.0003937 ,  0.00044171]),\n",
       "  array([1.02814916e-03, 1.94414061e-05, 2.44629685e-05]),\n",
       "  array([-0.06995799, -0.01925332, -0.00144673])],\n",
       " [array([-0.01634032,  0.04432896,  0.00087912]),\n",
       "  array([-0.27763762, -0.24957567, -0.25250733]),\n",
       "  array([-29.38422147, -54.77843728, -49.6483107 ])],\n",
       " array([195, 759, 612]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_segments_calc_trends_means(da_list,\n",
    "                                      inc_rand_error=True,\n",
    "                                      sample_length=150, sample_n=500,\n",
    "                                      verbose=False):\n",
    "    \"\"\"Draw n segments of specified length from DataArray list; return trends, means, start years (arrays).\"\"\"\n",
    "    # Identify possible start years from which to sample\n",
    "    poss_start_yrs = da_list[0].time.data[0:-sample_length+1]\n",
    "    if verbose:\n",
    "        print(f'Possible start years: {poss_start_yrs[0]} - {poss_start_yrs[-1]}')\n",
    "    # Randomly choose start years (with replacement)\n",
    "    rand_start_yrs = rng.choice(poss_start_yrs, size=sample_n, replace=True)\n",
    "    if verbose:\n",
    "        print(f'Randomly chosen start years: {rand_start_yrs}')\n",
    "    # Lists to hold trends and means for DataArrays in da_list    \n",
    "    trends_list = []\n",
    "    means_list = []\n",
    "    # Loop over DataArrays in list\n",
    "    for data_da in da_list:\n",
    "        # Calculate trends and means of the chosen time series segments\n",
    "        trends = np.zeros(sample_n)  # initialize arrays of trends/means with zero\n",
    "        means = np.zeros(sample_n)\n",
    "        for i in range(sample_n):\n",
    "            start_yr = rand_start_yrs[i]\n",
    "            sample_da = data_da.sel(time=slice(start_yr,start_yr+sample_length-1))\n",
    "            trends[i] = calc_trend(sample_da, inc_rand_error=inc_rand_error)\n",
    "            means[i] = calc_mean(sample_da, inc_rand_error=inc_rand_error)\n",
    "        if verbose:\n",
    "            print(f'Trends: {trends}')\n",
    "            print(f'Means: {means}')\n",
    "        trends_list.append(trends)\n",
    "        means_list.append(means)\n",
    "    return trends_list, means_list, rand_start_yrs\n",
    "\n",
    "# Example\n",
    "da_list = [da_dict[(source_member_list[-1], 'piControl', 'R')].copy(),\n",
    "           da_dict[(source_member_list[-1], 'piControl', 'H')].copy(),\n",
    "           da_dict[(source_member_list[-1], 'piControl', '\\Delta Z')].copy()]\n",
    "%time sample_segments_calc_trends_means(da_list, sample_n=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b21cf971-c93c-49aa-bd55-ea065901400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 17 14:43:04 +08 2022\n"
     ]
    }
   ],
   "source": [
    "! date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
